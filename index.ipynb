{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "# reddit-wiki-ripper\n",
    "by Jam#0001"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First things first, install the required packages:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: praw in c:\\users\\ojami\\appdata\\roaming\\python\\python38\\site-packages (7.1.0)\n",
      "Requirement already satisfied: regex in c:\\users\\ojami\\appdata\\roaming\\python\\python38\\site-packages (2020.10.28)\n",
      "Requirement already satisfied: update-checker>=0.17 in c:\\users\\ojami\\appdata\\roaming\\python\\python38\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: prawcore<2.0,>=1.3.0 in c:\\users\\ojami\\appdata\\roaming\\python\\python38\\site-packages (from praw) (1.5.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\ojami\\appdata\\roaming\\python\\python38\\site-packages (from praw) (0.57.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in c:\\users\\ojami\\appdata\\roaming\\python\\python38\\site-packages (from update-checker>=0.17->praw) (2.24.0)\n",
      "Requirement already satisfied: six in c:\\users\\ojami\\appdata\\roaming\\python\\python38\\site-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\ojami\\appdata\\roaming\\python\\python38\\site-packages (from requests>=2.3.0->update-checker>=0.17->praw) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ojami\\appdata\\roaming\\python\\python38\\site-packages (from requests>=2.3.0->update-checker>=0.17->praw) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ojami\\appdata\\roaming\\python\\python38\\site-packages (from requests>=2.3.0->update-checker>=0.17->praw) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ojami\\appdata\\roaming\\python\\python38\\site-packages (from requests>=2.3.0->update-checker>=0.17->praw) (2020.6.20)\n",
      "WARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install praw regex\n"
   ]
  },
  {
   "source": [
    "Go to the [reddit apps section](https://www.reddit.com/prefs/apps/) and create a new app.\n",
    "\n",
    "![app creation image](https://i.imgur.com/REpuvlH.png)\n",
    "\n",
    "Set the following as the client ID and secret\n",
    "\n",
    "![client ID and secret indicated image](https://i.imgur.com/kqdoRvW.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = input(\"Client ID: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_secret = input(\"Client Secret: \")"
   ]
  },
  {
   "source": [
    "Now input the subreddit you wish to grab the wiki from"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = input(\"Please enter a subreddit: \")"
   ]
  },
  {
   "source": [
    "Last step! Time to grab those wiki pages: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import regex\n",
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=\"reddit_wiki_ripper\"\n",
    ")\n",
    "\n",
    "# if not os.path.exists(os.path.join(\"./\", subreddit)):\n",
    "os.mkdir(os.path.join(\"./\", subreddit))\n",
    "\n",
    "for wikipage in reddit.subreddit(subreddit).wiki:\n",
    "    # if the subreddit is nested\n",
    "    if wikipage.name.find(\"/\") != -1:\n",
    "        dir = os.path.join(os.path.join(\"./\", subreddit), wikipage.name[:wikipage.name.rindex('/')])\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)\n",
    "    file_dir = os.path.join(os.path.join(\"./\", subreddit), wikipage.name)\n",
    "    with open(\"{}.md\".format(file_dir), \"w\", encoding=\"utf-8\") as f:\n",
    "        # fix headings\n",
    "        formatted_wikipage = regex.sub(r'(?<=\\n#?)#(?=[^# ])', \"# \", wikipage.content_md)\n",
    "        # replace links so they are to localhost rather than to reddit\n",
    "        formatted_wikipage = formatted_wikipage.replace(\"https://www.reddit.com/r/{}/wiki/\".format(subreddit), \"./\")\n",
    "        f.write(formatted_wikipage)"
   ]
  },
  {
   "source": [
    "If you are using google collab, run the following script to download all the files as a zip"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zipf = zipfile.ZipFile('wiki.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "for root, dirs, files in os.walk(os.path.join('./', subreddit)):\n",
    "    for file in files:\n",
    "        zipf.write(os.path.join(root, file))\n",
    "zipf.close()\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"/content/wiki.zip\")"
   ]
  }
 ]
}